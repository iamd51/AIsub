#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Whisper è­˜åˆ¥æº–ç¢ºåº¦å„ªåŒ–å™¨
å°ˆé–€è§£æ±º Whisper æ¨¡å‹è­˜åˆ¥ä¸æ­£ç¢ºçš„å•é¡Œ
"""

import os
import re
import json
import warnings
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
import difflib

# æŠ‘åˆ¶ Whisper è­¦å‘Š
warnings.filterwarnings("ignore", message=".*Failed to launch Triton kernels.*")
warnings.filterwarnings("ignore", message=".*falling back to a slower.*")

class WhisperAccuracyOptimizer:
    """Whisper è­˜åˆ¥æº–ç¢ºåº¦å„ªåŒ–å™¨"""
    
    def __init__(self):
        self.load_optimization_config()
        self.setup_language_specific_rules()
        
    def load_optimization_config(self):
        """è¼‰å…¥å„ªåŒ–é…ç½®"""
        self.optimization_config = {
            # åŸºç¤åƒæ•¸å„ªåŒ–
            "base_params": {
                "temperature": [0.0, 0.2, 0.5],  # å¤šæº«åº¦å˜—è©¦
                "no_speech_threshold": 0.6,
                "compression_ratio_threshold": 2.4,
                "logprob_threshold": -1.0,
                "condition_on_previous_text": False,
                "initial_prompt": None,
                "word_timestamps": True,
                "prepend_punctuations": "\"'([{-",
                "append_punctuations": "\"'.ã€‚,ï¼Œ!ï¼?ï¼Ÿ:ï¼š\")]}ã€",
            },
            
            # éŸ³æ¨‚æ¨¡å¼å„ªåŒ–
            "music_mode": {
                "temperature": [0.0, 0.3, 0.7],
                "no_speech_threshold": 0.3,
                "compression_ratio_threshold": 3.0,
                "logprob_threshold": -1.5,
                "best_of": 5,
                "beam_size": 5,
                "patience": 2.0,
                "length_penalty": 1.0,
                "suppress_tokens": [-1],  # ä¸æŠ‘åˆ¶ä»»ä½• token
                "without_timestamps": False,
            },
            
            # èªéŸ³æ¨¡å¼å„ªåŒ–
            "speech_mode": {
                "temperature": [0.0, 0.1],
                "no_speech_threshold": 0.6,
                "compression_ratio_threshold": 2.4,
                "logprob_threshold": -1.0,
                "best_of": 3,
                "beam_size": 3,
                "patience": 1.0,
                "length_penalty": 1.0,
            },
            
            # é«˜ç²¾åº¦æ¨¡å¼
            "high_accuracy_mode": {
                "temperature": [0.0],  # æœ€ä½æº«åº¦
                "no_speech_threshold": 0.8,
                "compression_ratio_threshold": 2.0,
                "logprob_threshold": -0.5,
                "best_of": 5,
                "beam_size": 5,
                "patience": 2.0,
                "length_penalty": 1.2,
            }
        }
    
    def setup_language_specific_rules(self):
        """è¨­å®šèªè¨€ç‰¹å®šçš„è¦å‰‡"""
        self.language_rules = {
            "ja": {
                "common_errors": {
                    # å¸¸è¦‹çš„æ—¥æ–‡è­˜åˆ¥éŒ¯èª¤ä¿®æ­£
                    "ã‚ã®": ["ã‚ã®ãƒ¼", "ã‚ã®ã†", "ã‚ã®ã€œ"],
                    "ãã†": ["ãã†ãƒ¼", "ãã†ã†", "ãã†ã€œ"],
                    "ã§ã™": ["ã§ãƒ¼ã™", "ã§ã™ãƒ¼"],
                    "ã¾ã™": ["ã¾ãƒ¼ã™", "ã¾ã™ãƒ¼"],
                    "ãã ã•ã„": ["ãã ã•ãƒ¼ã„", "ãã ã•ã„ã€œ"],
                    "ã‚ã‚ŠãŒã¨ã†": ["ã‚ã‚ŠãŒã¨ãƒ¼", "ã‚ã‚ŠãŒã¨ã†ãƒ¼"],
                    "ã“ã‚“ã«ã¡ã¯": ["ã“ã‚“ã«ã¡ã‚", "ã“ã‚“ã«ã¡ã¯ãƒ¼"],
                    "ã™ã¿ã¾ã›ã‚“": ["ã™ã„ã¾ã›ã‚“", "ã™ã¿ã¾ã›ãƒ¼ã‚“"],
                },
                "filter_patterns": [
                    r"^[ã‚ãƒ¼ã†ãƒ¼ãˆãƒ¼ãŠãƒ¼]+$",  # åªæœ‰é•·éŸ³çš„å…§å®¹
                    r"^[ã€‚ã€ï¼ï¼Ÿ]+$",  # åªæœ‰æ¨™é»ç¬¦è™Ÿ
                    r"^[â™ªâ™«â™¬â™©]+$",  # åªæœ‰éŸ³æ¨‚ç¬¦è™Ÿ
                    r"^[ãƒ»]+$",  # åªæœ‰ä¸­é»
                ],
                "meaningless_phrases": [
                    "ã‚ãƒ¼", "ã†ãƒ¼", "ãˆãƒ¼", "ãŠãƒ¼",
                    "ã‚“ãƒ¼", "ã†ã‚“", "ãˆãˆ",
                    "â™ª", "â™«", "â™¬", "â™©",
                    "ãƒ©ãƒ©ãƒ©", "ãƒŠãƒŠãƒŠ", "ãƒãƒãƒ",
                    "ä½œè©", "ä½œæ›²", "ç·¨æ›²",
                    "åˆéŸ³ãƒŸã‚¯", "ãƒœãƒ¼ã‚«ãƒ­ã‚¤ãƒ‰",
                ]
            },
            
            "en": {
                "common_errors": {
                    "yeah": ["yea", "yah", "ye"],
                    "okay": ["ok", "k"],
                    "alright": ["aight", "alrite"],
                    "because": ["cuz", "cos", "cause"],
                    "going to": ["gonna", "goin to"],
                    "want to": ["wanna", "wan to"],
                },
                "filter_patterns": [
                    r"^[aeiou]+$",  # åªæœ‰æ¯éŸ³
                    r"^[hmm]+$",  # hmm é¡è²éŸ³
                    r"^[uh]+$",  # uh é¡è²éŸ³
                ],
                "meaningless_phrases": [
                    "uh", "um", "er", "ah",
                    "hmm", "mhm", "mm",
                    "la la la", "na na na",
                    "music", "song", "lyrics",
                ]
            },
            
            "zh": {
                "common_errors": {
                    "é€™å€‹": ["é€™", "å€‹"],
                    "é‚£å€‹": ["é‚£", "å€‹"],
                    "ä»€éº¼": ["ç”šéº¼", "ä»€ä¹ˆ"],
                    "æ²’æœ‰": ["æ²’", "æœ‰"],
                    "å¯ä»¥": ["å¯", "ä»¥"],
                },
                "filter_patterns": [
                    r"^[å•Šå‘ƒå—¯å“¦]+$",  # èªæ°£è©
                    r"^[ã€‚ï¼Œï¼ï¼Ÿ]+$",  # æ¨™é»ç¬¦è™Ÿ
                ],
                "meaningless_phrases": [
                    "å•Š", "å‘ƒ", "å—¯", "å“¦",
                    "é€™å€‹", "é‚£å€‹", "ç„¶å¾Œ",
                    "å°±æ˜¯", "ç„¶å¾Œå°±",
                ]
            }
        }
    
    def optimize_whisper_params(self, 
                               content_type: str = "auto",
                               language: str = "auto",
                               quality_level: str = "high") -> Dict[str, Any]:
        """
        æ ¹æ“šå…§å®¹é¡å‹å’Œèªè¨€å„ªåŒ– Whisper åƒæ•¸
        
        Args:
            content_type: å…§å®¹é¡å‹ ("music", "speech", "mixed", "auto")
            language: èªè¨€ ("ja", "en", "zh", "auto")
            quality_level: å“è³ªç­‰ç´š ("fast", "balanced", "high", "ultra")
        
        Returns:
            å„ªåŒ–å¾Œçš„åƒæ•¸å­—å…¸
        """
        base_params = self.optimization_config["base_params"].copy()
        
        # æ ¹æ“šå…§å®¹é¡å‹èª¿æ•´åƒæ•¸
        if content_type == "music":
            base_params.update(self.optimization_config["music_mode"])
        elif content_type == "speech":
            base_params.update(self.optimization_config["speech_mode"])
        elif quality_level == "ultra":
            base_params.update(self.optimization_config["high_accuracy_mode"])
        
        # æ ¹æ“šèªè¨€èª¿æ•´åƒæ•¸
        if language == "ja":
            # æ—¥æ–‡ç‰¹æ®Šå„ªåŒ–
            base_params["initial_prompt"] = "ä»¥ä¸‹ã¯æ—¥æœ¬èªã®éŸ³å£°ã§ã™ã€‚æ­£ç¢ºã«è»¢å†™ã—ã¦ãã ã•ã„ã€‚"
            base_params["suppress_tokens"] = []  # ä¸æŠ‘åˆ¶æ—¥æ–‡ç‰¹æ®Šå­—ç¬¦
        elif language == "en":
            base_params["initial_prompt"] = "The following is English speech. Please transcribe accurately."
        elif language == "zh":
            base_params["initial_prompt"] = "ä»¥ä¸‹æ˜¯ä¸­æ–‡èªéŸ³ï¼Œè«‹æº–ç¢ºè½‰éŒ„ã€‚"
        
        # æ ¹æ“šå“è³ªç­‰ç´šèª¿æ•´
        if quality_level == "fast":
            base_params["temperature"] = [0.0]
            base_params["best_of"] = 1
        elif quality_level == "balanced":
            base_params["temperature"] = [0.0, 0.2]
            base_params["best_of"] = 3
        elif quality_level == "high":
            base_params["temperature"] = [0.0, 0.2, 0.5]
            base_params["best_of"] = 5
        elif quality_level == "ultra":
            base_params["temperature"] = [0.0, 0.1, 0.3, 0.5, 0.7]
            base_params["best_of"] = 5
            base_params["beam_size"] = 5
        
        return base_params
    
    def multi_pass_transcription(self, 
                                model, 
                                audio_file: str, 
                                params: Dict[str, Any],
                                language: str = "auto") -> Dict[str, Any]:
        """
        å¤šæ¬¡é€šéè½‰éŒ„ï¼Œé¸æ“‡æœ€ä½³çµæœ
        
        Args:
            model: Whisper æ¨¡å‹
            audio_file: éŸ³è¨Šæª”æ¡ˆè·¯å¾‘
            params: è½‰éŒ„åƒæ•¸
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            æœ€ä½³è½‰éŒ„çµæœ
        """
        results = []
        temperatures = params.get("temperature", [0.0])
        
        print(f"ğŸ”„ é–‹å§‹å¤šæ¬¡é€šéè½‰éŒ„ (æº«åº¦å€¼: {temperatures})")
        
        for i, temp in enumerate(temperatures):
            try:
                print(f"   ç¬¬ {i+1}/{len(temperatures)} æ¬¡ (æº«åº¦: {temp})")
                
                current_params = params.copy()
                current_params["temperature"] = temp
                
                # ç§»é™¤ä¸æ˜¯ Whisper API åƒæ•¸çš„é …ç›®
                whisper_params = {k: v for k, v in current_params.items() 
                                if k not in ["temperature"]}  # temperature æœƒå–®ç¨è™•ç†
                
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    result = model.transcribe(
                        audio_file, 
                        temperature=temp,
                        **whisper_params
                    )
                
                # è¨ˆç®—çµæœå“è³ªåˆ†æ•¸
                quality_score = self.calculate_quality_score(result, language)
                results.append({
                    "result": result,
                    "temperature": temp,
                    "quality_score": quality_score
                })
                
                print(f"   å“è³ªåˆ†æ•¸: {quality_score:.3f}")
                
            except Exception as e:
                print(f"   âš ï¸ æº«åº¦ {temp} è½‰éŒ„å¤±æ•—: {e}")
                continue
        
        if not results:
            raise Exception("æ‰€æœ‰æº«åº¦è¨­å®šéƒ½è½‰éŒ„å¤±æ•—")
        
        # é¸æ“‡å“è³ªåˆ†æ•¸æœ€é«˜çš„çµæœ
        best_result = max(results, key=lambda x: x["quality_score"])
        print(f"âœ… é¸æ“‡æœ€ä½³çµæœ (æº«åº¦: {best_result['temperature']}, åˆ†æ•¸: {best_result['quality_score']:.3f})")
        
        return best_result["result"]
    
    def calculate_quality_score(self, result: Dict[str, Any], language: str) -> float:
        """
        è¨ˆç®—è½‰éŒ„çµæœçš„å“è³ªåˆ†æ•¸
        
        Args:
            result: Whisper è½‰éŒ„çµæœ
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            å“è³ªåˆ†æ•¸ (0-1)
        """
        if not result.get("segments"):
            return 0.0
        
        total_score = 0.0
        total_segments = len(result["segments"])
        
        for segment in result["segments"]:
            segment_score = 0.0
            
            # 1. åŸºæ–¼å¹³å‡å°æ•¸æ©Ÿç‡çš„åˆ†æ•¸ (40%)
            if "avg_logprob" in segment:
                # å°‡å°æ•¸æ©Ÿç‡è½‰æ›ç‚º 0-1 åˆ†æ•¸
                logprob_score = max(0, min(1, (segment["avg_logprob"] + 3) / 3))
                segment_score += logprob_score * 0.4
            
            # 2. åŸºæ–¼å£“ç¸®æ¯”çš„åˆ†æ•¸ (20%)
            if "compression_ratio" in segment:
                # ç†æƒ³çš„å£“ç¸®æ¯”åœ¨ 1.5-2.5 ä¹‹é–“
                compression_ratio = segment["compression_ratio"]
                if 1.5 <= compression_ratio <= 2.5:
                    compression_score = 1.0
                elif compression_ratio < 1.5:
                    compression_score = compression_ratio / 1.5
                else:
                    compression_score = max(0, 1 - (compression_ratio - 2.5) / 2.5)
                segment_score += compression_score * 0.2
            
            # 3. åŸºæ–¼æ–‡å­—å“è³ªçš„åˆ†æ•¸ (30%)
            text = segment.get("text", "").strip()
            text_score = self.evaluate_text_quality(text, language)
            segment_score += text_score * 0.3
            
            # 4. åŸºæ–¼æ™‚é–“ä¸€è‡´æ€§çš„åˆ†æ•¸ (10%)
            duration = segment.get("end", 0) - segment.get("start", 0)
            if duration > 0 and len(text) > 0:
                # ç†æƒ³çš„èªé€Ÿç´„ç‚ºæ¯ç§’ 2-8 å€‹å­—ç¬¦
                chars_per_second = len(text) / duration
                if 2 <= chars_per_second <= 8:
                    timing_score = 1.0
                elif chars_per_second < 2:
                    timing_score = chars_per_second / 2
                else:
                    timing_score = max(0, 1 - (chars_per_second - 8) / 8)
                segment_score += timing_score * 0.1
            
            total_score += segment_score
        
        return total_score / total_segments if total_segments > 0 else 0.0
    
    def evaluate_text_quality(self, text: str, language: str) -> float:
        """
        è©•ä¼°æ–‡å­—å“è³ª
        
        Args:
            text: è¦è©•ä¼°çš„æ–‡å­—
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            æ–‡å­—å“è³ªåˆ†æ•¸ (0-1)
        """
        if not text or len(text.strip()) < 2:
            return 0.0
        
        score = 1.0
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å«ç„¡æ„ç¾©çš„å…§å®¹
        if language in self.language_rules:
            rules = self.language_rules[language]
            
            # æª¢æŸ¥éæ¿¾æ¨¡å¼
            for pattern in rules.get("filter_patterns", []):
                if re.match(pattern, text.strip()):
                    score *= 0.1
                    break
            
            # æª¢æŸ¥ç„¡æ„ç¾©çŸ­èª
            for phrase in rules.get("meaningless_phrases", []):
                if phrase in text.lower():
                    score *= 0.5
        
        # æª¢æŸ¥é‡è¤‡å­—ç¬¦
        if len(set(text.replace(" ", ""))) < len(text.replace(" ", "")) * 0.3:
            score *= 0.6  # å­—ç¬¦é‡è¤‡åº¦å¤ªé«˜
        
        # æª¢æŸ¥é•·åº¦åˆç†æ€§
        if len(text) < 3:
            score *= 0.7
        elif len(text) > 200:
            score *= 0.9  # å¤ªé•·çš„å¥å­å¯èƒ½æœ‰å•é¡Œ
        
        return score
    
    def post_process_segments(self, 
                             segments: List[Dict[str, Any]], 
                             language: str = "auto",
                             filter_repetitive: bool = True,
                             merge_short_segments: bool = True) -> List[Dict[str, Any]]:
        """
        å¾Œè™•ç†è½‰éŒ„ç‰‡æ®µ
        
        Args:
            segments: åŸå§‹ç‰‡æ®µåˆ—è¡¨
            language: èªè¨€ä»£ç¢¼
            filter_repetitive: æ˜¯å¦éæ¿¾é‡è¤‡å…§å®¹
            merge_short_segments: æ˜¯å¦åˆä½µçŸ­ç‰‡æ®µ
        
        Returns:
            è™•ç†å¾Œçš„ç‰‡æ®µåˆ—è¡¨
        """
        if not segments:
            return []
        
        print(f"ğŸ”§ é–‹å§‹å¾Œè™•ç† {len(segments)} å€‹ç‰‡æ®µ")
        
        # 1. åŸºæœ¬æ¸…ç†
        cleaned_segments = []
        for segment in segments:
            text = segment.get("text", "").strip()
            
            # è·³éç©ºç™½å…§å®¹
            if not text or len(text) < 2:
                continue
            
            # èªè¨€ç‰¹å®šçš„æ¸…ç†
            if language in self.language_rules:
                text = self.clean_text_by_language(text, language)
                if not text:
                    continue
            
            segment["text"] = text
            cleaned_segments.append(segment)
        
        print(f"   æ¸…ç†å¾Œå‰©é¤˜: {len(cleaned_segments)} å€‹ç‰‡æ®µ")
        
        # 2. éæ¿¾é‡è¤‡å…§å®¹
        if filter_repetitive:
            cleaned_segments = self.filter_repetitive_segments(cleaned_segments)
            print(f"   éæ¿¾é‡è¤‡å¾Œå‰©é¤˜: {len(cleaned_segments)} å€‹ç‰‡æ®µ")
        
        # 3. åˆä½µçŸ­ç‰‡æ®µ
        if merge_short_segments:
            cleaned_segments = self.merge_short_segments(cleaned_segments)
            print(f"   åˆä½µçŸ­ç‰‡æ®µå¾Œå‰©é¤˜: {len(cleaned_segments)} å€‹ç‰‡æ®µ")
        
        # 4. æœ€çµ‚å“è³ªæª¢æŸ¥
        final_segments = []
        for segment in cleaned_segments:
            text_quality = self.evaluate_text_quality(segment["text"], language)
            if text_quality > 0.3:  # åªä¿ç•™å“è³ªåˆ†æ•¸ > 0.3 çš„ç‰‡æ®µ
                final_segments.append(segment)
        
        print(f"âœ… æœ€çµ‚ä¿ç•™: {len(final_segments)} å€‹é«˜å“è³ªç‰‡æ®µ")
        return final_segments
    
    def clean_text_by_language(self, text: str, language: str) -> str:
        """
        æ ¹æ“šèªè¨€æ¸…ç†æ–‡å­—
        
        Args:
            text: åŸå§‹æ–‡å­—
            language: èªè¨€ä»£ç¢¼
        
        Returns:
            æ¸…ç†å¾Œçš„æ–‡å­—
        """
        if language not in self.language_rules:
            return text
        
        rules = self.language_rules[language]
        
        # æª¢æŸ¥éæ¿¾æ¨¡å¼
        for pattern in rules.get("filter_patterns", []):
            if re.match(pattern, text.strip()):
                return ""  # å®Œå…¨éæ¿¾æ‰
        
        # ä¿®æ­£å¸¸è¦‹éŒ¯èª¤
        for correct, errors in rules.get("common_errors", {}).items():
            for error in errors:
                text = text.replace(error, correct)
        
        # ç§»é™¤ç„¡æ„ç¾©çŸ­èªï¼ˆå¦‚æœæ•´å€‹æ–‡å­—å°±æ˜¯ç„¡æ„ç¾©çŸ­èªï¼‰
        meaningless = rules.get("meaningless_phrases", [])
        if text.strip().lower() in [phrase.lower() for phrase in meaningless]:
            return ""
        
        return text.strip()
    
    def filter_repetitive_segments(self, segments: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éæ¿¾é‡è¤‡çš„ç‰‡æ®µ"""
        if len(segments) <= 1:
            return segments
        
        filtered = [segments[0]]  # ä¿ç•™ç¬¬ä¸€å€‹ç‰‡æ®µ
        
        for current in segments[1:]:
            current_text = current["text"].strip().lower()
            
            # æª¢æŸ¥èˆ‡å‰é¢å¹¾å€‹ç‰‡æ®µçš„ç›¸ä¼¼åº¦
            is_repetitive = False
            for prev in filtered[-3:]:  # æª¢æŸ¥æœ€è¿‘3å€‹ç‰‡æ®µ
                prev_text = prev["text"].strip().lower()
                
                # å®Œå…¨ç›¸åŒ
                if current_text == prev_text:
                    is_repetitive = True
                    break
                
                # é«˜åº¦ç›¸ä¼¼
                similarity = difflib.SequenceMatcher(None, current_text, prev_text).ratio()
                if similarity > 0.8:
                    is_repetitive = True
                    break
                
                # åŒ…å«é—œä¿‚
                if len(current_text) > 10 and len(prev_text) > 10:
                    if current_text in prev_text or prev_text in current_text:
                        is_repetitive = True
                        break
            
            if not is_repetitive:
                filtered.append(current)
        
        return filtered
    
    def merge_short_segments(self, segments: List[Dict[str, Any]], 
                           min_duration: float = 1.0,
                           max_gap: float = 2.0) -> List[Dict[str, Any]]:
        """
        åˆä½µéçŸ­çš„ç‰‡æ®µ
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            min_duration: æœ€å°æŒçºŒæ™‚é–“ï¼ˆç§’ï¼‰
            max_gap: æœ€å¤§é–“éš”æ™‚é–“ï¼ˆç§’ï¼‰
        
        Returns:
            åˆä½µå¾Œçš„ç‰‡æ®µåˆ—è¡¨
        """
        if len(segments) <= 1:
            return segments
        
        merged = []
        current_segment = segments[0].copy()
        
        for next_segment in segments[1:]:
            current_duration = current_segment["end"] - current_segment["start"]
            gap = next_segment["start"] - current_segment["end"]
            
            # å¦‚æœç•¶å‰ç‰‡æ®µå¤ªçŸ­ä¸”èˆ‡ä¸‹ä¸€å€‹ç‰‡æ®µé–“éš”ä¸å¤§ï¼Œå‰‡åˆä½µ
            if current_duration < min_duration and gap <= max_gap:
                # åˆä½µæ–‡å­—å’Œæ™‚é–“
                current_segment["text"] += " " + next_segment["text"]
                current_segment["end"] = next_segment["end"]
                
                # åˆä½µå…¶ä»–å±¬æ€§ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if "avg_logprob" in current_segment and "avg_logprob" in next_segment:
                    # åŠ æ¬Šå¹³å‡
                    w1 = current_duration
                    w2 = next_segment["end"] - next_segment["start"]
                    total_weight = w1 + w2
                    if total_weight > 0:
                        current_segment["avg_logprob"] = (
                            current_segment["avg_logprob"] * w1 + 
                            next_segment["avg_logprob"] * w2
                        ) / total_weight
            else:
                # ä¸åˆä½µï¼Œä¿å­˜ç•¶å‰ç‰‡æ®µä¸¦é–‹å§‹æ–°çš„ç‰‡æ®µ
                merged.append(current_segment)
                current_segment = next_segment.copy()
        
        # æ·»åŠ æœ€å¾Œä¸€å€‹ç‰‡æ®µ
        merged.append(current_segment)
        
        return merged
    
    def generate_optimized_srt(self, 
                              result: Dict[str, Any], 
                              language: str = "auto",
                              filter_repetitive: bool = True,
                              merge_short_segments: bool = True) -> str:
        """
        ç”Ÿæˆå„ªåŒ–çš„ SRT å­—å¹•
        
        Args:
            result: Whisper è½‰éŒ„çµæœ
            language: èªè¨€ä»£ç¢¼
            filter_repetitive: æ˜¯å¦éæ¿¾é‡è¤‡å…§å®¹
            merge_short_segments: æ˜¯å¦åˆä½µçŸ­ç‰‡æ®µ
        
        Returns:
            SRT æ ¼å¼å­—å¹•å…§å®¹
        """
        if not result.get("segments"):
            return ""
        
        # å¾Œè™•ç†ç‰‡æ®µ
        processed_segments = self.post_process_segments(
            result["segments"],
            language=language,
            filter_repetitive=filter_repetitive,
            merge_short_segments=merge_short_segments
        )
        
        # ç”Ÿæˆ SRT å…§å®¹
        srt_content = ""
        for i, segment in enumerate(processed_segments, 1):
            start_time = self.seconds_to_srt_time(segment["start"])
            end_time = self.seconds_to_srt_time(segment["end"])
            text = segment["text"].strip()
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        return srt_content
    
    def seconds_to_srt_time(self, seconds: float) -> str:
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def save_optimization_report(self, 
                                original_segments: int,
                                final_segments: int,
                                quality_scores: List[float],
                                output_path: str):
        """ä¿å­˜å„ªåŒ–å ±å‘Š"""
        report = {
            "optimization_summary": {
                "original_segments": original_segments,
                "final_segments": final_segments,
                "reduction_rate": (original_segments - final_segments) / original_segments if original_segments > 0 else 0,
                "average_quality_score": sum(quality_scores) / len(quality_scores) if quality_scores else 0,
                "min_quality_score": min(quality_scores) if quality_scores else 0,
                "max_quality_score": max(quality_scores) if quality_scores else 0,
            },
            "recommendations": self.generate_recommendations(original_segments, final_segments, quality_scores)
        }
        
        report_path = output_path.replace(".srt", "_optimization_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“Š å„ªåŒ–å ±å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    def generate_recommendations(self, 
                               original_segments: int,
                               final_segments: int,
                               quality_scores: List[float]) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []
        
        if not quality_scores:
            return ["ç„¡æ³•ç”Ÿæˆå»ºè­°ï¼šç¼ºå°‘å“è³ªåˆ†æ•¸è³‡æ–™"]
        
        avg_quality = sum(quality_scores) / len(quality_scores)
        reduction_rate = (original_segments - final_segments) / original_segments if original_segments > 0 else 0
        
        if avg_quality < 0.5:
            recommendations.append("å»ºè­°ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹ï¼ˆå¦‚ largeï¼‰ä»¥æé«˜è­˜åˆ¥æº–ç¢ºåº¦")
            recommendations.append("è€ƒæ…®ä½¿ç”¨é«˜å“è³ªçš„éŸ³è¨Šæª”æ¡ˆä½œç‚ºè¼¸å…¥")
            recommendations.append("æª¢æŸ¥éŸ³è¨Šå“è³ªï¼Œç¢ºä¿æ²’æœ‰éå¤šèƒŒæ™¯å™ªéŸ³")
        
        if reduction_rate > 0.5:
            recommendations.append("éæ¿¾äº†å¤§é‡ç‰‡æ®µï¼Œå¯èƒ½éœ€è¦èª¿æ•´éæ¿¾åƒæ•¸")
            recommendations.append("è€ƒæ…®é™ä½å“è³ªé–¾å€¼ä»¥ä¿ç•™æ›´å¤šå…§å®¹")
        
        if reduction_rate < 0.1:
            recommendations.append("éæ¿¾æ•ˆæœæœ‰é™ï¼Œå¯èƒ½éœ€è¦åŠ å¼·å¾Œè™•ç†")
            recommendations.append("è€ƒæ…®å•Ÿç”¨æ›´åš´æ ¼çš„é‡è¤‡å…§å®¹éæ¿¾")
        
        if avg_quality > 0.8:
            recommendations.append("è­˜åˆ¥å“è³ªè‰¯å¥½ï¼Œç•¶å‰è¨­å®šé©åˆæ­¤é¡å…§å®¹")
        
        return recommendations if recommendations else ["ç•¶å‰å„ªåŒ–æ•ˆæœè‰¯å¥½ï¼Œç„¡éœ€ç‰¹åˆ¥èª¿æ•´"]


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    optimizer = WhisperAccuracyOptimizer()
    
    # ç¤ºä¾‹ï¼šå„ªåŒ–éŸ³æ¨‚å…§å®¹çš„åƒæ•¸
    music_params = optimizer.optimize_whisper_params(
        content_type="music",
        language="ja",
        quality_level="ultra"
    )
    
    print("ğŸµ éŸ³æ¨‚æ¨¡å¼å„ªåŒ–åƒæ•¸:")
    for key, value in music_params.items():
        print(f"   {key}: {value}")